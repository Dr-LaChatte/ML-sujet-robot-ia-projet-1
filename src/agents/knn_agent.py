"""
Agent k-NN pour le ML supervisÃ©.
Apprend Ã  imiter la politique Q-learning Ã  partir du dataset gÃ©nÃ©rÃ©.
"""

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pickle
import os
import sys
from typing import Tuple, Dict, Optional

# Ajouter le chemin parent pour les imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.config import (
    KNN_NEIGHBORS, KNN_WEIGHTS,
    TEST_SIZE, VALIDATION_SIZE,
    KNN_MODEL_FILE, ACTION_NAMES, NUM_ACTIONS
)


class KNNAgent:
    """
    Agent k-NN pour l'apprentissage supervisÃ©.
    
    Imite la politique apprise par Q-learning en classifiant
    les Ã©tats pour prÃ©dire les actions.
    """
    
    def __init__(
        self,
        n_neighbors: int = KNN_NEIGHBORS,
        weights: str = KNN_WEIGHTS
    ):
        """
        Initialise l'agent k-NN.
        
        Args:
            n_neighbors: Nombre de voisins
            weights: PondÃ©ration ('uniform' ou 'distance')
        """
        self.n_neighbors = n_neighbors
        self.weights = weights
        
        self.model = KNeighborsClassifier(
            n_neighbors=n_neighbors,
            weights=weights,
            algorithm='auto',
            metric='euclidean'
        )
        
        # DonnÃ©es d'entraÃ®nement
        self.X_train = None
        self.X_val = None
        self.X_test = None
        self.y_train = None
        self.y_val = None
        self.y_test = None
        
        # MÃ©triques
        self.metrics = {}
        self.is_trained = False
    
    def prepare_data(
        self,
        X: np.ndarray,
        y: np.ndarray,
        test_size: float = TEST_SIZE,
        val_size: float = VALIDATION_SIZE,
        random_state: int = 42
    ) -> Dict:
        """
        PrÃ©pare les donnÃ©es en sÃ©parant train/val/test.
        
        Args:
            X: Features (Ã©tats)
            y: Labels (actions)
            test_size: Proportion pour le test
            val_size: Proportion pour la validation
            random_state: Graine alÃ©atoire
            
        Returns:
            Dictionnaire avec les tailles des ensembles
        """
        # PremiÃ¨re sÃ©paration : train+val vs test
        X_temp, self.X_test, y_temp, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # DeuxiÃ¨me sÃ©paration : train vs val
        val_ratio = val_size / (1 - test_size)
        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(
            X_temp, y_temp, test_size=val_ratio, random_state=random_state, stratify=y_temp
        )
        
        data_info = {
            'train_size': len(self.X_train),
            'val_size': len(self.X_val),
            'test_size': len(self.X_test),
            'total_size': len(X),
            'n_features': X.shape[1] if len(X.shape) > 1 else 1,
            'n_classes': len(np.unique(y)),
            'class_distribution': {
                int(c): int(np.sum(y == c)) for c in np.unique(y)
            }
        }
        
        print("\nğŸ“Š PrÃ©paration des donnÃ©es:")
        print(f"   Train: {data_info['train_size']} ({100*(1-test_size-val_size):.0f}%)")
        print(f"   Validation: {data_info['val_size']} ({100*val_size:.0f}%)")
        print(f"   Test: {data_info['test_size']} ({100*test_size:.0f}%)")
        print(f"   Classes: {data_info['class_distribution']}")
        
        return data_info
    
    def train(self) -> Dict:
        """
        EntraÃ®ne le modÃ¨le k-NN.
        
        Returns:
            Dictionnaire avec les mÃ©triques d'entraÃ®nement
        """
        if self.X_train is None:
            raise ValueError("DonnÃ©es non prÃ©parÃ©es. Appeler prepare_data() d'abord.")
        
        print(f"\nğŸ“ EntraÃ®nement k-NN (k={self.n_neighbors}, weights={self.weights})...")
        
        # EntraÃ®nement
        self.model.fit(self.X_train, self.y_train)
        self.is_trained = True
        
        # Ã‰valuation sur validation
        y_val_pred = self.model.predict(self.X_val)
        val_accuracy = accuracy_score(self.y_val, y_val_pred)
        
        # Validation croisÃ©e
        cv_scores = cross_val_score(self.model, self.X_train, self.y_train, cv=5)
        
        self.metrics['train'] = {
            'val_accuracy': val_accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'cv_scores': cv_scores.tolist()
        }
        
        print(f"   âœ… Accuracy validation: {val_accuracy:.4f}")
        print(f"   âœ… Cross-validation: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")
        
        return self.metrics['train']
    
    def evaluate(self) -> Dict:
        """
        Ã‰value le modÃ¨le sur l'ensemble de test.
        
        Returns:
            Dictionnaire avec les mÃ©triques d'Ã©valuation
        """
        if not self.is_trained:
            raise ValueError("ModÃ¨le non entraÃ®nÃ©. Appeler train() d'abord.")
        
        print("\nğŸ“ˆ Ã‰valuation sur l'ensemble de test...")
        
        # PrÃ©dictions
        y_pred = self.model.predict(self.X_test)
        
        # MÃ©triques
        accuracy = accuracy_score(self.y_test, y_pred)
        conf_matrix = confusion_matrix(self.y_test, y_pred)
        class_report = classification_report(
            self.y_test, y_pred,
            target_names=[ACTION_NAMES[i] for i in range(NUM_ACTIONS)],
            output_dict=True
        )
        
        self.metrics['test'] = {
            'accuracy': accuracy,
            'confusion_matrix': conf_matrix.tolist(),
            'classification_report': class_report
        }
        
        print(f"   âœ… Accuracy test: {accuracy:.4f}")
        print("\nğŸ“Š Matrice de confusion:")
        print(f"   {'':12s} PrÃ©dit â†’")
        print(f"   {'RÃ©el â†“':12s} {'Monter':>8s} {'Rester':>8s} {'Descendre':>10s}")
        for i, row in enumerate(conf_matrix):
            print(f"   {ACTION_NAMES[i]:12s} {row[0]:>8d} {row[1]:>8d} {row[2]:>10d}")
        
        print("\nğŸ“‹ Rapport de classification:")
        for action_id, action_name in ACTION_NAMES.items():
            if action_name in class_report:
                stats = class_report[action_name]
                print(f"   {action_name:12s} - PrÃ©cision: {stats['precision']:.3f}, "
                      f"Rappel: {stats['recall']:.3f}, F1: {stats['f1-score']:.3f}")
        
        return self.metrics['test']
    
    def choose_action(self, state: np.ndarray) -> int:
        """
        Choisit une action pour un Ã©tat donnÃ©.
        
        Args:
            state: Ã‰tat (array de features)
            
        Returns:
            Action prÃ©dite
        """
        if not self.is_trained:
            raise ValueError("ModÃ¨le non entraÃ®nÃ©.")
        
        if len(state.shape) == 1:
            state = state.reshape(1, -1)
        
        return int(self.model.predict(state)[0])
    
    def choose_action_from_components(
        self,
        shuttle_lane: int,
        distance_state: int,
        obstacle_lane: int
    ) -> int:
        """
        Choisit une action Ã  partir des composantes d'Ã©tat.
        
        Args:
            shuttle_lane: Ligne de la navette
            distance_state: Distance discrÃ©tisÃ©e (0=proche, 1=moyen, 2=loin)
            obstacle_lane: Ligne de l'obstacle
            
        Returns:
            Action prÃ©dite
        """
        state = np.array([[shuttle_lane, distance_state, obstacle_lane]])
        return self.choose_action(state)
    
    def get_action_probabilities(self, state: np.ndarray) -> np.ndarray:
        """
        Retourne les probabilitÃ©s pour chaque action (basÃ© sur les voisins).
        
        Args:
            state: Ã‰tat
            
        Returns:
            Array de probabilitÃ©s pour chaque action
        """
        if not self.is_trained:
            raise ValueError("ModÃ¨le non entraÃ®nÃ©.")
        
        if len(state.shape) == 1:
            state = state.reshape(1, -1)
        
        # Trouver les k voisins
        distances, indices = self.model.kneighbors(state)
        neighbor_labels = self.y_train[indices[0]]
        
        # Calculer les probabilitÃ©s
        probs = np.zeros(NUM_ACTIONS)
        for label in neighbor_labels:
            probs[label] += 1
        probs /= len(neighbor_labels)
        
        return probs
    
    def save(self, filepath: str = None):
        """
        Sauvegarde le modÃ¨le k-NN.
        
        Args:
            filepath: Chemin du fichier
        """
        if filepath is None:
            filepath = KNN_MODEL_FILE
        
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'wb') as f:
            pickle.dump({
                'model': self.model,
                'metrics': self.metrics,
                'n_neighbors': self.n_neighbors,
                'weights': self.weights
            }, f)
        
        print(f"âœ… ModÃ¨le k-NN sauvegardÃ©: {filepath}")
    
    def load(self, filepath: str = None):
        """
        Charge un modÃ¨le k-NN sauvegardÃ©.
        
        Args:
            filepath: Chemin du fichier
        """
        if filepath is None:
            filepath = KNN_MODEL_FILE
        
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
        
        self.model = data['model']
        self.metrics = data['metrics']
        self.n_neighbors = data['n_neighbors']
        self.weights = data['weights']
        self.is_trained = True
        
        print(f"âœ… ModÃ¨le k-NN chargÃ©: {filepath}")
        if 'test' in self.metrics:
            print(f"   Accuracy: {self.metrics['test']['accuracy']:.4f}")


def find_best_k(X: np.ndarray, y: np.ndarray, k_range: range = range(1, 21)) -> Dict:
    """
    Trouve le meilleur k par validation croisÃ©e.
    
    Args:
        X: Features
        y: Labels
        k_range: Plage de valeurs de k Ã  tester
        
    Returns:
        Dictionnaire avec les rÃ©sultats
    """
    print("\nğŸ” Recherche du meilleur k...")
    
    results = []
    
    for k in k_range:
        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')
        scores = cross_val_score(knn, X, y, cv=5)
        results.append({
            'k': k,
            'mean_score': scores.mean(),
            'std_score': scores.std()
        })
        print(f"   k={k:2d}: {scores.mean():.4f} (+/- {scores.std()*2:.4f})")
    
    best = max(results, key=lambda x: x['mean_score'])
    print(f"\n   ğŸ† Meilleur k = {best['k']} (accuracy = {best['mean_score']:.4f})")
    
    return {
        'best_k': best['k'],
        'best_score': best['mean_score'],
        'all_results': results
    }
