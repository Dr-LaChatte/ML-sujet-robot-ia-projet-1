"""
Script de d√©monstration visuelle.
Lance la simulation avec un agent (RL ou ML) pour visualiser le comportement.
"""

import sys
import os
import argparse
import time

# Ajouter le chemin du projet
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import Q_TABLE_FILE, KNN_MODEL_FILE, MAX_STEPS_PER_EPISODE, FPS
from src.environment.warehouse_env import WarehouseEnv
from src.agents.q_learning_agent import QLearningAgent
from src.agents.knn_agent import KNNAgent


def run_demo(
    agent_type: str = 'rl',
    agent_path: str = None,
    num_episodes: int = 5,
    max_steps: int = MAX_STEPS_PER_EPISODE,
    speed: float = 1.0
):
    """
    Lance une d√©monstration visuelle.
    
    Args:
        agent_type: 'rl' ou 'ml'
        agent_path: Chemin de l'agent
        num_episodes: Nombre d'√©pisodes √† jouer
        max_steps: Nombre max de pas par √©pisode
        speed: Vitesse de simulation (1.0 = normal)
    """
    print("=" * 60)
    print("üéÆ D√âMONSTRATION VISUELLE")
    print("=" * 60)
    
    # Charger l'agent
    print(f"\nüì• Chargement de l'agent {agent_type.upper()}...")
    
    if agent_type == 'rl':
        agent = QLearningAgent()
        if agent_path is None:
            agent_path = Q_TABLE_FILE
        try:
            agent.load(agent_path)
        except FileNotFoundError:
            print(f"\n‚ùå Erreur: Agent RL non trouv√© √† {agent_path}")
            print("   Veuillez d'abord ex√©cuter train_rl.py")
            return
    else:
        agent = KNNAgent()
        if agent_path is None:
            agent_path = KNN_MODEL_FILE
        try:
            agent.load(agent_path)
        except FileNotFoundError:
            print(f"\n‚ùå Erreur: Agent ML non trouv√© √† {agent_path}")
            print("   Veuillez d'abord ex√©cuter train_ml.py")
            return
    
    print(f"   ‚úÖ Agent charg√©: {agent_path}")
    
    # Cr√©er l'environnement avec affichage
    env = WarehouseEnv(render_mode='human')
    
    print(f"\nüìã Configuration:")
    print(f"   Agent: {agent_type.upper()}")
    print(f"   √âpisodes: {num_episodes}")
    print(f"   Max pas/√©pisode: {max_steps}")
    print(f"   Vitesse: {speed}x")
    
    print(f"\nüöÄ Lancement de la d√©monstration...")
    print("   (Fermez la fen√™tre pour quitter)")
    
    total_rewards = []
    total_avoidances = 0
    total_collisions = 0
    
    for episode in range(num_episodes):
        state, _ = env.reset()
        episode_reward = 0
        avoidances = 0
        
        print(f"\n   üìç √âpisode {episode + 1}/{num_episodes}")
        
        for step in range(max_steps):
            # Choisir l'action
            if agent_type == 'rl':
                action = agent.choose_action(state, training=False)
            else:
                components = env.get_state_components()
                action = agent.choose_action_from_components(*components)
            
            # Ex√©cuter l'action
            next_state, reward, terminated, _, info = env.step(action)
            episode_reward += reward
            
            if reward > 0:
                avoidances += 1
                total_avoidances += 1
            
            # Afficher
            continue_rendering = env.render()
            
            if not continue_rendering:
                print("\n   ‚ùå Fen√™tre ferm√©e.")
                env.close()
                return
            
            # Ajuster la vitesse
            if speed < 1.0:
                time.sleep((1.0 - speed) * 0.02)
            
            if terminated:
                total_collisions += 1
                print(f"      üí• Collision apr√®s {step + 1} pas (√©vitements: {avoidances})")
                break
            
            state = next_state
        
        if not terminated:
            print(f"      ‚úÖ Surv√©cu {max_steps} pas (√©vitements: {avoidances})")
        
        total_rewards.append(episode_reward)
        
        # Pause entre les √©pisodes
        time.sleep(0.5)
    
    # R√©sum√©
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â DE LA D√âMONSTRATION")
    print("=" * 60)
    print(f"\n   Agent: {agent_type.upper()}")
    print(f"   √âpisodes: {num_episodes}")
    print(f"   R√©compense totale: {sum(total_rewards):.0f}")
    print(f"   R√©compense moyenne: {sum(total_rewards)/len(total_rewards):.1f}")
    print(f"   √âvitements: {total_avoidances}")
    print(f"   Collisions: {total_collisions}")
    print(f"   Taux de survie: {100*(num_episodes-total_collisions)/num_episodes:.1f}%")
    
    print("\n   Fermez la fen√™tre pour quitter...")
    
    # Garder la fen√™tre ouverte
    import pygame
    running = True
    while running:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                running = False
    
    env.close()
    print("\n‚úÖ D√©monstration termin√©e!")


def run_manual_mode():
    """
    Mode manuel : contr√¥le de la navette au clavier.
    """
    print("=" * 60)
    print("üéÆ MODE MANUEL")
    print("=" * 60)
    print("\n   Contr√¥les:")
    print("   ‚Üë (Fl√®che haut) : Monter")
    print("   ‚Üì (Fl√®che bas)  : Descendre")
    print("   Espace          : Rester")
    print("   R               : Recommencer")
    print("   Q / √âchap       : Quitter")
    
    import pygame
    
    env = WarehouseEnv(render_mode='human')
    state, _ = env.reset()
    
    running = True
    total_reward = 0
    avoidances = 0
    
    while running:
        action = 1  # Rester par d√©faut
        
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                running = False
            elif event.type == pygame.KEYDOWN:
                if event.key == pygame.K_UP:
                    action = 0  # Monter
                elif event.key == pygame.K_DOWN:
                    action = 2  # Descendre
                elif event.key == pygame.K_SPACE:
                    action = 1  # Rester
                elif event.key == pygame.K_r:
                    state, _ = env.reset()
                    total_reward = 0
                    avoidances = 0
                    print("\n   üîÑ Nouvelle partie!")
                elif event.key in (pygame.K_q, pygame.K_ESCAPE):
                    running = False
        
        if running:
            state, reward, terminated, _, _ = env.step(action)
            total_reward += reward
            
            if reward > 0:
                avoidances += 1
            
            env.render()
            
            if terminated:
                print(f"\n   üí• Collision! Score: {total_reward:.0f}, √âvitements: {avoidances}")
                print("   Appuyez sur R pour recommencer ou Q pour quitter.")
    
    env.close()
    print("\n‚úÖ Mode manuel termin√©!")


def main():
    parser = argparse.ArgumentParser(
        description="D√©monstration visuelle de la navette robotique"
    )
    parser.add_argument(
        '--agent', '-a',
        type=str,
        choices=['rl', 'ml', 'manual'],
        default='rl',
        help="Type d'agent (rl, ml, ou manual pour jouer)"
    )
    parser.add_argument(
        '--path', '-p',
        type=str,
        default=None,
        help="Chemin de l'agent"
    )
    parser.add_argument(
        '--episodes', '-e',
        type=int,
        default=5,
        help="Nombre d'√©pisodes (d√©faut: 5)"
    )
    parser.add_argument(
        '--max-steps', '-s',
        type=int,
        default=MAX_STEPS_PER_EPISODE,
        help=f"Max pas par √©pisode (d√©faut: {MAX_STEPS_PER_EPISODE})"
    )
    parser.add_argument(
        '--speed',
        type=float,
        default=1.0,
        help="Vitesse de simulation (d√©faut: 1.0)"
    )
    
    args = parser.parse_args()
    
    if args.agent == 'manual':
        run_manual_mode()
    else:
        run_demo(
            agent_type=args.agent,
            agent_path=args.path,
            num_episodes=args.episodes,
            max_steps=args.max_steps,
            speed=args.speed
        )


if __name__ == "__main__":
    main()
